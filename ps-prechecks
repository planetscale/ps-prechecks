#!/bin/bash

# This program is a derivative of pt-mysql-summary, which is a part 
# of Percona Toolkit: http://www.percona.com/software/
# See "COPYRIGHT, LICENSE, AND WARRANTY" at the end of this file for legal
# notices and disclaimers.

set -u

# ###########################################################################
# log_warn_die package
# This package is a copy without comments from the original.  The original
# with comments and its test file can be found in the GitHub repository at,
#   lib/bash/log_warn_die.sh
#   t/lib/bash/log_warn_die.sh
# See https://github.com/percona/percona-toolkit for more information.
# ###########################################################################


set -u

PSFUNCNAME=""
PSDEBUG="${PSDEBUG:-""}"
EXIT_STATUS=0

ts() {
   TS=$(date +%F-%T | tr ':-' '_')
   echo "$TS $*"
}

info() {
   [ ${OPT_VERBOSE:-3} -ge 3 ] && ts "$*"
}

log() {
   [ ${OPT_VERBOSE:-3} -ge 2 ] && ts "$*"
}

warn() {
   [ ${OPT_VERBOSE:-3} -ge 1 ] && ts "$*" >&2
   EXIT_STATUS=1
}

die() {
   ts "$*" >&2
   EXIT_STATUS=1
   exit 1
}

_d () {
   [ "$PSDEBUG" ] && echo "# $PSFUNCNAME: $(ts "$*")" >&2
}

# ###########################################################################
# End log_warn_die package
# ###########################################################################

# ###########################################################################
# parse_options package
# This package is a copy without comments from the original.  The original
# with comments and its test file can be found in the GitHub repository at,
#   lib/bash/parse_options.sh
#   t/lib/bash/parse_options.sh
# See https://github.com/percona/percona-toolkit for more information.
# ###########################################################################





set -u

ARGV=""           # Non-option args (probably input files)
EXT_ARGV=""       # Everything after -- (args for an external command)
HAVE_EXT_ARGV=""  # Got --, everything else is put into EXT_ARGV
OPT_ERRS=0        # How many command line option errors
OPT_VERSION=""    # If --version was specified
OPT_HELP=""       # If --help was specified
OPT_ASK_PASS=""   # If --ask-pass was specified
OPT_TXT=""        # If --txt was specified
TIMESTAMP=""      # For report and samples folders
PO_DIR=""         # Directory with program option spec files
SAMPLES_DIR=""    # Directory with saved samples

usage() {
   local file="$1"

   local usage="$(grep '^Usage: ' "$file")"
   echo $usage
   echo
   echo "For more information, 'man $TOOL' or 'perldoc $file'."
}

usage_or_errors() {
   local file="$1"
   local version=""

   if [ "$OPT_VERSION" ]; then
      version=$(grep '^pt-[^ ]\+ [0-9]' "$file")
      echo "$version"
      return 1
   fi

   if [ "$OPT_HELP" ]; then
      usage "$file"
      echo
      echo "Command line options:"
      echo
      perl -e '
         use strict;
         use warnings FATAL => qw(all);
         my $lcol = 20;         # Allow this much space for option names.
         my $rcol = 80 - $lcol; # The terminal is assumed to be 80 chars wide.
         my $name;
         while ( <> ) {
            my $line = $_;
            chomp $line;
            if ( $line =~ s/^long:/  --/ ) {
               $name = $line;
            }
            elsif ( $line =~ s/^desc:// ) {
               $line =~ s/ +$//mg;
               my @lines = grep { $_      }
                           $line =~ m/(.{0,$rcol})(?:\s+|\Z)/g;
               if ( length($name) >= $lcol ) {
                  print $name, "\n", (q{ } x $lcol);
               }
               else {
                  printf "%-${lcol}s", $name;
               }
               print join("\n" . (q{ } x $lcol), @lines);
               print "\n";
            }
         }
      ' "$PO_DIR"/*
      echo
      echo "Options and values after processing arguments:"
      echo
      (
         cd "$PO_DIR"
         for opt in *; do
            local varname="OPT_$(echo "$opt" | tr a-z- A-Z_)"
            eval local varvalue=\$$varname
            if ! grep -q "type:" "$PO_DIR/$opt" >/dev/null; then
               if [ "$varvalue" -a "$varvalue" = "yes" ];
                  then varvalue="TRUE"
               else
                  varvalue="FALSE"
               fi
            fi
            printf -- "  --%-30s %s" "$opt" "${varvalue:-(No value)}"
            echo
         done
      )
      echo
      echo "Example command:"
      echo
      echo "     ./ps-prechecks --host <hostname> --user <user> --port 3306 --ask-pass --sleep 60"
      echo 
      echo "  The above command collects data from two status snapshots with 60 seconds in between."
      echo "  It saves the sampled information in a folder called 'ps_samples_[timestamp]' and produces"
      echo "  an archive of both its output, the sample files and the included freeform questionnaire."
      echo
      echo "  Feel free to review and edit these files as necessary, and be careful not to share sensitive"
      echo "  information. If you choose not to share all collected data, your PlanetScale representative" 
      echo "  may ask you to provide additional information at a later stage."
      echo 
      return 1
   fi

   if [ $OPT_ERRS -gt 0 ]; then
      echo
      usage "$file"
      return 1
   fi

   return 0
}

option_error() {
   local err="$1"
   OPT_ERRS=$(($OPT_ERRS + 1))
   echo "$err" >&2
}

parse_options() {
   local file="$1"
   shift

   ARGV=""
   EXT_ARGV=""
   HAVE_EXT_ARGV=""
   OPT_ERRS=0
   OPT_VERSION=""
   OPT_HELP=""
   OPT_ASK_PASS=""
   OPT_TXT=""
   PO_DIR="$PS_TMPDIR/po"

   if [ ! -d "$PO_DIR" ]; then
      mkdir "$PO_DIR"
      if [ $? -ne 0 ]; then
         echo "Cannot mkdir $PO_DIR" >&2
         exit 1
      fi
   fi

   rm -rf "$PO_DIR"/*
   if [ $? -ne 0 ]; then
      echo "Cannot rm -rf $PO_DIR/*" >&2
      exit 1
   fi

   _parse_pod "$file"  # Parse POD into program option (po) spec files
   _eval_po            # Eval po into existence with default values

   if [ $# -ge 2 ] &&  [ "$1" = "--config" ]; then
      shift  # --config
      local user_config_files="$1"
      shift  # that ^
      local IFS=","
      for user_config_file in $user_config_files; do
         _parse_config_files "$user_config_file"
      done
   else
      _parse_config_files "/etc/percona-toolkit/percona-toolkit.conf" "/etc/percona-toolkit/$TOOL.conf"
      if [ "${HOME:-}" ]; then
         _parse_config_files "$HOME/.percona-toolkit.conf" "$HOME/.$TOOL.conf"
      fi
   fi

   _parse_command_line "${@:-""}"
}

_parse_pod() {
   local file="$1"

   PO_FILE="$file" PO_DIR="$PO_DIR" perl -e '
      $/ = "";
      my $file = $ENV{PO_FILE};
      open my $fh, "<", $file or die "Cannot open $file: $!";
      while ( defined(my $para = <$fh>) ) {
         next unless $para =~ m/^=head1 OPTIONS/;
         while ( defined(my $para = <$fh>) ) {
            last if $para =~ m/^=head1/;
            chomp;
            if ( $para =~ m/^=item --(\S+)/ ) {
               my $opt  = $1;
               my $file = "$ENV{PO_DIR}/$opt";
               open my $opt_fh, ">", $file or die "Cannot open $file: $!";
               print $opt_fh "long:$opt\n";
               $para = <$fh>;
               chomp;
               if ( $para =~ m/^[a-z ]+:/ ) {
                  map {
                     chomp;
                     my ($attrib, $val) = split(/: /, $_);
                     print $opt_fh "$attrib:$val\n";
                  } split(/; /, $para);
                  $para = <$fh>;
                  chomp;
               }
               my ($desc) = $para =~ m/^([^?.]+)/;
               print $opt_fh "desc:$desc.\n";
               close $opt_fh;
            }
         }
         last;
      }
   '
}

_eval_po() {
   local IFS=":"
   for opt_spec in "$PO_DIR"/*; do
      local opt=""
      local default_val=""
      local neg=0
      local size=0
      while read key val; do
         case "$key" in
            long)
               opt=$(echo $val | sed 's/-/_/g' | tr '[:lower:]' '[:upper:]')
               ;;
            default)
               default_val="$val"
               ;;
            "short form")
               ;;
            type)
               [ "$val" = "size" ] && size=1
               ;;
            desc)
               ;;
            negatable)
               if [ "$val" = "yes" ]; then
                  neg=1
               fi
               ;;
            *)
               echo "Invalid attribute in $opt_spec: $line" >&2
               exit 1
         esac 
      done < "$opt_spec"

      if [ -z "$opt" ]; then
         echo "No long attribute in option spec $opt_spec" >&2
         exit 1
      fi

      if [ $neg -eq 1 ]; then
         if [ -z "$default_val" ] || [ "$default_val" != "yes" ]; then
            echo "Option $opt_spec is negatable but not default: yes" >&2
            exit 1
         fi
      fi

      if [ $size -eq 1 -a -n "$default_val" ]; then
         default_val=$(size_to_bytes $default_val)
      fi

      eval "OPT_${opt}"="$default_val"
   done
}

_parse_config_files() {

   for config_file in "${@:-""}"; do
      test -f "$config_file" || continue

      while read config_opt; do

         echo "$config_opt" | grep '^[ ]*[^#]' >/dev/null 2>&1 || continue

         config_opt="$(echo "$config_opt" | sed -e 's/^ *//g' -e 's/ *$//g' -e 's/[ ]*=[ ]*/=/' -e 's/[ ]+#.*$//')"

         [ "$config_opt" = "" ] && continue

         echo "$config_opt" | grep -v 'version-check' >/dev/null 2>&1 || continue

         if ! [ "$HAVE_EXT_ARGV" ]; then
            config_opt="--$config_opt"
         fi

         _parse_command_line "$config_opt"

      done < "$config_file"

      HAVE_EXT_ARGV=""  # reset for each file

   done
}

_parse_command_line() {
   local opt=""
   local val=""
   local next_opt_is_val=""
   local opt_is_ok=""
   local opt_is_negated=""
   local real_opt=""
   local required_arg=""
   local spec=""

   for opt in "${@:-""}"; do
      if [ "$opt" = "--" -o "$opt" = "----" ]; then
         HAVE_EXT_ARGV=1
         continue
      fi
      if [ "$HAVE_EXT_ARGV" ]; then
         if [ "$EXT_ARGV" ]; then
            EXT_ARGV="$EXT_ARGV $opt"
         else
            EXT_ARGV="$opt"
         fi
         continue
      fi

      if [ "$next_opt_is_val" ]; then
         next_opt_is_val=""
         if [ $# -eq 0 ] || [ $(expr "$opt" : "\-") -eq 1 ]; then
            option_error "$real_opt requires a $required_arg argument"
            continue
         fi
         val="$opt"
         opt_is_ok=1
      else
         if [ $(expr "$opt" : "\-") -eq 0 ]; then
            if [ -z "$ARGV" ]; then
               ARGV="$opt"
            else
               ARGV="$ARGV $opt"
            fi
            continue
         fi

         real_opt="$opt"

         if $(echo $opt | grep '^--no[^-]' >/dev/null); then
            local base_opt=$(echo $opt | sed 's/^--no//')
            if [ -f "$PS_TMPDIR/po/$base_opt" ]; then
               opt_is_negated=1
               opt="$base_opt"
            else
               opt_is_negated=""
               opt=$(echo $opt | sed 's/^-*//')
            fi
         else
            if $(echo $opt | grep '^--no-' >/dev/null); then
               opt_is_negated=1
               opt=$(echo $opt | sed 's/^--no-//')
            else
               opt_is_negated=""
               opt=$(echo $opt | sed 's/^-*//')
            fi
         fi

         if $(echo $opt | grep '^[a-z-][a-z-]*=' >/dev/null 2>&1); then
            val="$(echo $opt | awk -F= '{print $2}')"
            opt="$(echo $opt | awk -F= '{print $1}')"
         fi

         if [ -f "$PS_TMPDIR/po/$opt" ]; then
            spec="$PS_TMPDIR/po/$opt"
         else
            spec=$(grep "^short form:-$opt\$" "$PS_TMPDIR"/po/* | cut -d ':' -f 1)
            if [ -z "$spec"  ]; then
               continue
            fi
         fi

         required_arg=$(cat "$spec" | awk -F: '/^type:/{print $2}')
         if [ "$required_arg" ]; then
            if [ "$val" ]; then
               opt_is_ok=1
            else
               next_opt_is_val=1
            fi
         else
            if [ "$val" ]; then
               option_error "Option $real_opt does not take a value"
               continue
            fi 
            if [ "$opt_is_negated" ]; then
               val=""
            else
               val="yes"
            fi
            opt_is_ok=1
         fi
      fi

      if [ "$opt_is_ok" ]; then
         opt=$(cat "$spec" | grep '^long:' | cut -d':' -f2 | sed 's/-/_/g' | tr '[:lower:]' '[:upper:]')

         if grep "^type:size" "$spec" >/dev/null; then
            val=$(size_to_bytes $val)
         fi

         eval "OPT_$opt"="'$val'"

         opt=""
         val=""
         next_opt_is_val=""
         opt_is_ok=""
         opt_is_negated=""
         real_opt=""
         required_arg=""
         spec=""
      fi
   done
}

size_to_bytes() {
   local size="$1"
   echo $size | perl -ne '%f=(B=>1, K=>1_024, M=>1_048_576, G=>1_073_741_824, T=>1_099_511_627_776); m/^(\d+)([kMGT])?/i; print $1 * $f{uc($2 || "B")};'
}

# ###########################################################################
# End parse_options package
# ###########################################################################

# ###########################################################################
# mysql_options package
# This package is a copy without comments from the original.  The original
# with comments and its test file can be found in the GitHub repository at,
#   lib/bash/mysql_options.sh
#   t/lib/bash/mysql_options.sh
# See https://github.com/percona/percona-toolkit for more information.
# ###########################################################################


set -u

mysql_options() {
   local MYSQL_ARGS=""
   if [ -n "$OPT_DEFAULTS_FILE" ]; then
      MYSQL_ARGS="--defaults-file=$OPT_DEFAULTS_FILE"
   fi
   if [ -n "$OPT_PORT" ]; then
      MYSQL_ARGS="$MYSQL_ARGS --port=$OPT_PORT"
   fi
   if [ -n "$OPT_SOCKET" ]; then
      MYSQL_ARGS="$MYSQL_ARGS --socket=$OPT_SOCKET"
   fi
   if [ -n "$OPT_HOST" ]; then
      MYSQL_ARGS="$MYSQL_ARGS --host=$OPT_HOST"
   fi
   if [ -n "$OPT_USER" ]; then
      MYSQL_ARGS="$MYSQL_ARGS --user=$OPT_USER"
   fi
   if [ -n "$OPT_ASK_PASS" ]; then
      stty -echo
      >&2 printf "Enter MySQL password: "
      read GIVEN_PASS 
      stty echo
      printf "\n"
      MYSQL_ARGS="$MYSQL_ARGS --password=$GIVEN_PASS"
   elif [ -n "$OPT_PASSWORD" ]; then
      MYSQL_ARGS="$MYSQL_ARGS --password=$OPT_PASSWORD"
   fi
   
   echo $MYSQL_ARGS
}

arrange_mysql_options() {
   local opts="$1"
   
   local rearranged=""
   for opt in $opts; do
      if [ "$(echo $opt | awk -F= '{print $1}')" = "--defaults-file" ]; then
          rearranged="$opt $rearranged"
      else
         rearranged="$rearranged $opt"
      fi
   done
   
   echo "$rearranged"
}

# ###########################################################################
# End mysql_options package
# ###########################################################################

# ###########################################################################
# tmpdir package
# This package is a copy without comments from the original.  The original
# with comments and its test file can be found in the GitHub repository at,
#   lib/bash/tmpdir.sh
#   t/lib/bash/tmpdir.sh
# See https://github.com/percona/percona-toolkit for more information.
# ###########################################################################


set -u

PS_TMPDIR=""

mk_tmpdir() {
   local dir="${1:-""}"

   if [ -n "$dir" ]; then
      if [ ! -d "$dir" ]; then
         mkdir "$dir" || die "Cannot make tmpdir $dir"
      fi
      PS_TMPDIR="$dir"
   else
      local tool="${0##*/}"
      local pid="$$"
      PS_TMPDIR=`mktemp -d -t "${tool}.${pid}.XXXXXX"` \
         || die "Cannot make secure tmpdir"
   fi
}

rm_tmpdir() {
   if [ -n "$PS_TMPDIR" ] && [ -d "$PS_TMPDIR" ]; then
      rm -rf "$PS_TMPDIR"
   fi
   PS_TMPDIR=""
}

# ###########################################################################
# End tmpdir package
# ###########################################################################

# ###########################################################################
# alt_cmds package
# This package is a copy without comments from the original.  The original
# with comments and its test file can be found in the GitHub repository at,
#   lib/bash/alt_cmds.sh
#   t/lib/bash/alt_cmds.sh
# See https://github.com/percona/percona-toolkit for more information.
# ###########################################################################


set -u

_seq() {
   local i="$1"
   awk "BEGIN { for(i=1; i<=$i; i++) print i; }"
}

_pidof() {
   local cmd="$1"
   if ! pidof "$cmd" 2>/dev/null; then
      ps -eo pid,ucomm | awk -v comm="$cmd" '$2 == comm { print $1 }'
   fi
}

_lsof() {
   local pid="$1"
   if ! lsof -p $pid 2>/dev/null; then
      /bin/ls -l /proc/$pid/fd 2>/dev/null
   fi
}



_which() {
   if [ -x /usr/bin/which ]; then
      /usr/bin/which "$1" 2>/dev/null | awk '{print $1}'
   elif which which 1>/dev/null 2>&1; then
      which "$1" 2>/dev/null | awk '{print $1}'
   else
      echo "$1"
   fi
}

# ###########################################################################
# End alt_cmds package
# ###########################################################################

# ###########################################################################
# report_formatting package
# This package is a copy without comments from the original.  The original
# with comments and its test file can be found in the GitHub repository at,
#   lib/bash/report_formatting.sh
#   t/lib/bash/report_formatting.sh
# See https://github.com/percona/percona-toolkit for more information.
# ###########################################################################


set -u

POSIXLY_CORRECT=1
export POSIXLY_CORRECT

fuzzy_formula='
   rounded = 0;
   if (fuzzy_var <= 10 ) {
      rounded   = 1;
   }
   factor = 1;
   while ( rounded == 0 ) {
      if ( fuzzy_var <= 50 * factor ) {
         fuzzy_var = sprintf("%.0f", fuzzy_var / (5 * factor)) * 5 * factor;
         rounded   = 1;
      }
      else if ( fuzzy_var <= 100  * factor) {
         fuzzy_var = sprintf("%.0f", fuzzy_var / (10 * factor)) * 10 * factor;
         rounded   = 1;
      }
      else if ( fuzzy_var <= 250  * factor) {
         fuzzy_var = sprintf("%.0f", fuzzy_var / (25 * factor)) * 25 * factor;
         rounded   = 1;
      }
      factor = factor * 10;
   }'

fuzz () {
   awk -v fuzzy_var="$1" "BEGIN { ${fuzzy_formula} print fuzzy_var;}"
}

fuzzy_pct () {
   local pct="$(awk -v one="$1" -v two="$2" 'BEGIN{ if (two > 0) { printf "%d", one/two*100; } else {print 0} }')";
   echo "$(fuzz "${pct}")%"
}

section () {
   local str="$1"
   if [ -n "$OPT_TXT" ]; then
      awk -v var="${str} _" 'BEGIN {
         line = sprintf("# %-60s", var);
         i = index(line, "_");
         x = substr(line, i);
         gsub(/[_ \t]/, "#", x);
         printf("%s%s\n", substr(line, 1, i-1), x);
      }'
   else
      echo "## ${str}"
   fi
   
}

NAME_VAL_LEN=35
name_val () {
   printf "%+*s | %s\n" "${NAME_VAL_LEN}" "$1" "$2"
}

shorten() {
   local num="$1"
   local prec="${2:-2}"
   local div="${3:-1024}"

   echo "$num" | awk -v prec="$prec" -v div="$div" '
      {
         num  = $1;
         unit = num >= 1125899906842624 ? "P" \
              : num >= 1099511627776    ? "T" \
              : num >= 1073741824       ? "G" \
              : num >= 1048576          ? "M" \
              : num >= 1024             ? "k" \
              :                           "";
         while ( num >= div ) {
            num /= div;
         }
         printf "%.*f%s", prec, num, unit;
      }
   '
}

group_concat () {
   sed -e '{H; $!d;}' -e 'x' -e 's/\n[[:space:]]*\([[:digit:]]*\)[[:space:]]*/, \1x/g' -e 's/[[:space:]][[:space:]]*/ /g' -e 's/, //' "${1}"
}

# ###########################################################################
# End report_formatting package
# ###########################################################################

# ###########################################################################
# summary_common package
# This package is a copy without comments from the original.  The original
# with comments and its test file can be found in the GitHub repository at,
#   lib/bash/summary_common.sh
#   t/lib/bash/summary_common.sh
# See https://github.com/percona/percona-toolkit for more information.
# ###########################################################################


set -u

CMD_FILE="$( _which file 2>/dev/null )"
CMD_NM="$( _which nm 2>/dev/null )"
CMD_OBJDUMP="$( _which objdump 2>/dev/null )"

get_nice_of_pid () {
   local pid="$1"
   local niceness="$(ps -p $pid -o nice | awk '$1 !~ /[^0-9]/ {print $1; exit}')"

   if [ -n "${niceness}" ]; then
      echo $niceness
   else
      local tmpfile="$PS_TMPDIR/nice_through_c.tmp.c"
      _d "Getting the niceness from ps failed, somehow. We are about to try this:"
      cat <<EOC > "$tmpfile"

int main(void) {
   int priority = getpriority(PRIO_PROCESS, $pid);
   if ( priority == -1 && errno == ESRCH ) {
      return 1;
   }
   else {
      printf("%d\\n", priority);
      return 0;
   }
}

EOC
      local c_comp=$(_which gcc)
      if [ -z "${c_comp}" ]; then
         c_comp=$(_which cc)
      fi
      _d "$tmpfile: $( cat "$tmpfile" )"
      _d "$c_comp -xc \"$tmpfile\" -o \"$tmpfile\" && eval \"$tmpfile\""
      $c_comp -xc "$tmpfile" -o "$tmpfile" 2>/dev/null && eval "$tmpfile" 2>/dev/null
      if [ $? -ne 0 ]; then
         echo "?"
         _d "Failed to get a niceness value for $pid"
      fi
   fi
}

get_oom_of_pid () {
   local pid="$1"
   local oom_adj=""

   if [ -n "${pid}" -a -e /proc/cpuinfo ]; then
      if [ -s "/proc/$pid/oom_score_adj" ]; then
         oom_adj=$(cat "/proc/$pid/oom_score_adj" 2>/dev/null)
         _d "For $pid, the oom value is $oom_adj, retreived from oom_score_adj"
      else
         oom_adj=$(cat "/proc/$pid/oom_adj" 2>/dev/null)
         _d "For $pid, the oom value is $oom_adj, retreived from oom_adj"
      fi
   fi

   if [ -n "${oom_adj}" ]; then
      echo "${oom_adj}"
   else
      echo "?"
      _d "Can't find the oom value for $pid"
   fi
}

has_symbols () {
   local executable="$(_which "$1")"
   local has_symbols=""

   if    [ "${CMD_FILE}" ] \
      && [ "$($CMD_FILE "${executable}" | grep 'not stripped' )" ]; then
      has_symbols=1
   elif    [ "${CMD_NM}" ] \
        || [ "${CMD_OBJDMP}" ]; then
      if    [ "${CMD_NM}" ] \
         && [ !"$("${CMD_NM}" -- "${executable}" 2>&1 | grep 'File format not recognized' )" ]; then
         if [ -z "$( $CMD_NM -- "${executable}" 2>&1 | grep ': no symbols' )" ]; then
            has_symbols=1
         fi
      elif [ -z "$("${CMD_OBJDUMP}" -t -- "${executable}" | grep '^no symbols$' )" ]; then
         has_symbols=1
      fi
   fi

   if [ "${has_symbols}" ]; then
      echo "Yes"
   else
      echo "No"
   fi
}

setup_data_dir () {
   local existing_dir="$1"
   local data_dir=""
   if [ -z "$existing_dir" ]; then
      mkdir "ps_samples_$TIMESTAMP" || die "Cannot mkdir ps_samples_$TIMESTAMP"
      data_dir="ps_samples_$TIMESTAMP"
   else
      if [ ! -d "$existing_dir" ]; then
         mkdir "$existing_dir" || die "Cannot mkdir $existing_dir"
      elif [ "$( ls -A "$existing_dir" )" ]; then
         die "--save-samples directory isn't empty, halting."
      fi
      touch "$existing_dir/test" || die "Cannot write to $existing_dir"
      rm "$existing_dir/test"    || die "Cannot rm $existing_dir/test"
      data_dir="$existing_dir"
   fi
   SAMPLES_DIR=$data_dir
   echo "$data_dir"
}

get_var () {
   local varname="$1"
   local file="$2"
   awk -v pattern="${varname}" '$1 == pattern { if (length($2)) { len = length($1); print substr($0, len+index(substr($0, len+1), $2)) } }' "${file}"
}

# ###########################################################################
# End summary_common package
# ###########################################################################

# ###########################################################################
# collect_mysql_info package
# This package is a copy without comments from the original.  The original
# with comments and its test file can be found in the GitHub repository at,
#   lib/bash/collect_mysql_info.sh
#   t/lib/bash/collect_mysql_info.sh
# See https://github.com/percona/percona-toolkit for more information.
# ###########################################################################



CMD_MYSQL="${CMD_MYSQL:-""}"
CMD_MYSQLDUMP="${CMD_MYSQLDUMP:-""}"

collect_mysqld_instances () {
   local variables_file="$1"

   local pids="$(_pidof mysqld)"

   if [ -n "$pids" ]; then

      for pid in $pids; do
         local nice="$( get_nice_of_pid $pid )"
         local oom="$( get_oom_of_pid $pid )"
         echo "internal::nice_of_$pid    $nice" >> "$variables_file"
         echo "internal::oom_of_$pid    $oom" >> "$variables_file"
      done

      pids="$(echo $pids | sed -e 's/ /,/g')"
      ps ww -p "$pids" 2>/dev/null
   else
      echo "mysqld doesn't appear to be running"
   fi

}

find_my_cnf_file() {
   local file="$1"
   local port="${2:-""}"

   local cnf_file=""

   if [ "$port" ]; then
      cnf_file="$(grep --max-count 1 "/mysqld.*--port=$port" "$file" \
         | awk 'BEGIN{RS=" "; FS="=";} $1 ~ /--defaults-file/ { print $2; }')"
   else
      cnf_file="$(grep --max-count 1 '/mysqld' "$file" \
         | awk 'BEGIN{RS=" "; FS="=";} $1 ~ /--defaults-file/ { print $2; }')"
   fi

   if [ -z "$cnf_file" ]; then
      if [ -e "/etc/my.cnf" ]; then
         cnf_file="/etc/my.cnf"
      elif [ -e "/etc/mysql/my.cnf" ]; then
         cnf_file="/etc/mysql/my.cnf"
      elif [ -e "/var/db/mysql/my.cnf" ]; then
         cnf_file="/var/db/mysql/my.cnf";
      fi
   fi

   echo "$cnf_file"
}

collect_table_sizes () {
   local total="$($CMD_MYSQL $EXT_ARGV -ss -e "SELECT SUM(data_length+index_length) AS size FROM information_schema.tables WHERE table_schema NOT IN ('information_schema','mysql','performance_schema','sys','_vt');" 2>/dev/null)"
   echo "Total    $total"   
   $CMD_MYSQL $EXT_ARGV -ss -e "SELECT CONCAT(table_schema,'.',table_name), SUM(data_length+index_length) AS total_length, CONCAT(' (',SUM(table_rows),' rows)') AS table_rows_txt FROM information_schema.tables WHERE table_schema NOT IN ('information_schema','mysql','performance_schema','sys','_vt') GROUP BY table_schema, table_name ORDER BY total_length DESC, sum(table_rows) DESC, table_name ASC;" 2>/dev/null
}

collect_mysql_variables () {
   $CMD_MYSQL $EXT_ARGV -ss  -e 'SHOW /*!40100 GLOBAL*/ VARIABLES'
}

collect_mysql_status () {
   $CMD_MYSQL $EXT_ARGV -ss -e 'SHOW /*!50000 GLOBAL*/ STATUS'
}

collect_mysql_databases () {
   $CMD_MYSQL $EXT_ARGV -ss -e 'SHOW DATABASES' 2>/dev/null
}

collect_mysql_replica_status () {
   $CMD_MYSQL $EXT_ARGV -ssE -e 'SHOW SLAVE STATUS' 2>/dev/null
}

collect_mysql_processlist () {
   $CMD_MYSQL $EXT_ARGV -ssE -e 'SHOW FULL PROCESSLIST' 2>/dev/null
}

collect_master_logs_status () {
   local master_logs_file="$1"
   local master_status_file="$2"
   $CMD_MYSQL $EXT_ARGV -ss -e 'SHOW MASTER LOGS' > "$master_logs_file" 2>/dev/null
   $CMD_MYSQL $EXT_ARGV -ss -e 'SHOW MASTER STATUS' > "$master_status_file" 2>/dev/null
}

collect_mysql_deferred_status () {
   local status_file="$1"
   collect_mysql_status > "$PS_TMPDIR/defer_gatherer"
   join "$status_file" "$PS_TMPDIR/defer_gatherer"
}

collect_internal_vars () {
   local mysqld_executables="${1:-""}"

   local FNV_64=""
   if $CMD_MYSQL $EXT_ARGV -e 'SELECT FNV_64("a")' >/dev/null 2>&1; then
      FNV_64="Enabled";
   else
      FNV_64="Unknown";
   fi

   local now="$($CMD_MYSQL $EXT_ARGV -ss -e 'SELECT NOW()')"
   local user="$($CMD_MYSQL $EXT_ARGV -ss -e 'SELECT CURRENT_USER()')"
   local trigger_count=$($CMD_MYSQL $EXT_ARGV -ss -e "SELECT COUNT(*) FROM INFORMATION_SCHEMA.TRIGGERS" 2>/dev/null)

   echo "pt-summary-internal-mysql_executable    $CMD_MYSQL"
   echo "pt-summary-internal-now    $now"
   echo "pt-summary-internal-user   $user"
   echo "pt-summary-internal-FNV_64   $FNV_64"
   echo "pt-summary-internal-trigger_count   $trigger_count"

   if [ -e "$mysqld_executables" ]; then
      local i=1
      while read executable; do
         echo "pt-summary-internal-mysqld_executable_${i}   $(has_symbols "$executable")"
         i=$(($i + 1))
      done < "$mysqld_executables"
   fi
}

get_mysqldump_for () {
   local args="$1"
   local dbtodump="${2:-"--all-databases"}"

   $CMD_MYSQLDUMP $EXT_ARGV --no-data --skip-comments \
      --skip-add-locks --skip-add-drop-table --compact \
      --skip-lock-all-tables --skip-lock-tables --skip-set-charset \
      ${args} --databases $(local IFS=,; echo ${dbtodump})
}

get_mysqldump_args () {
   local file="$1"
   local trg_arg=""

   if $CMD_MYSQLDUMP --help --verbose 2>&1 | grep triggers >/dev/null; then
      trg_arg="--routines"
   fi

   if [ "${trg_arg}" ]; then
      local triggers="--skip-triggers"
      local trg=$(get_var "pt-summary-internal-trigger_count" "$file" )
      if [ -n "${trg}" ] && [ "${trg}" -gt 0 ]; then
         triggers="--triggers"
      fi
      trg_arg="${trg_arg} ${triggers}";
   fi
   echo "${trg_arg}"
}

collect_mysqld_executables () {
   local mysqld_instances="$1"

   local ps_opt="cmd="
   if [ "$(uname -s)" = "Darwin" ]; then
      ps_opt="command="
   fi

   for pid in $( grep '/mysqld' "$mysqld_instances" | awk '/^.*[0-9]/{print $1}' ); do
      ps -o $ps_opt -p $pid | sed -e 's/^\(.*mysqld\) .*/\1/'
   done | sort -u
}

collect_mysql_info () {
   local dir="$1"

   collect_table_sizes         > "$dir/table-sizes"
   collect_mysql_variables     > "$dir/mysql-variables"
   collect_mysql_status        > "$dir/mysql-status"
   collect_mysql_databases     > "$dir/mysql-databases"
   collect_mysql_replica_status  > "$dir/mysql-replica"
   collect_mysql_processlist   > "$dir/mysql-processlist"   

   collect_mysqld_instances   "$dir/mysql-variables"  > "$dir/mysqld-instances"
   collect_mysqld_executables "$dir/mysqld-instances" > "$dir/mysqld-executables"

   local binlog="$(get_var log_bin "$dir/mysql-variables")"
   if [ "${binlog}" ]; then
      collect_master_logs_status "$dir/mysql-master-logs" "$dir/mysql-master-status"
   fi

   local uptime="$(get_var Uptime "$dir/mysql-status")"
   local current_time="$($CMD_MYSQL $EXT_ARGV -ss -e \
                         "SELECT LEFT(NOW() - INTERVAL ${uptime} SECOND, 16)")"

   local port="$(get_var port "$dir/mysql-variables")"
   local cnf_file="$(find_my_cnf_file "$dir/mysqld-instances" ${port})"

   [ -e "$cnf_file" ] && cat "$cnf_file" > "$dir/mysql-config-file"

   local pid_file="$(get_var "pid_file" "$dir/mysql-variables")"
   local pid_file_exists=""
   [ -e "${pid_file}" ] && pid_file_exists=1
   echo "pt-summary-internal-pid_file_exists    $pid_file_exists" >> "$dir/mysql-variables"

   echo "pt-summary-internal-current_time    $current_time" >> "$dir/mysql-variables"
   echo "pt-summary-internal-Config_File_path    $cnf_file" >> "$dir/mysql-variables"
   collect_internal_vars "$dir/mysqld-executables" >> "$dir/mysql-variables"

   if [ "$OPT_DATABASES" -o "$OPT_ALL_DATABASES" ]; then
      local trg_arg="$(get_mysqldump_args "$dir/mysql-variables")"
      local dbs="${OPT_DATABASES:-""}"
      get_mysqldump_for "${trg_arg}" "$dbs" > "$dir/mysqldump"
   fi

   (
      sleep $OPT_SLEEP
      collect_mysql_deferred_status "$dir/mysql-status" > "$dir/mysql-status-defer"
   ) &
   _d "Forked child is $!"
}

# ###########################################################################
# End collect_mysql_info package
# ###########################################################################

# ###########################################################################
# report_mysql_info package
# This package is a copy without comments from the original.  The original
# with comments and its test file can be found in the GitHub repository at,
#   lib/bash/report_mysql_info.sh
#   t/lib/bash/report_mysql_info.sh
# See https://github.com/percona/percona-toolkit for more information.
# ###########################################################################


set -u
POSIXLY_CORRECT=1

secs_to_time () {
   awk -v sec="$1" 'BEGIN {
      printf( "%d+%02d:%02d:%02d", sec / 86400, (sec % 86400) / 3600, (sec % 3600) / 60, sec % 60);
   }'
}

feat_on() {
   local file="$1"
   local varname="$2"
   [ -e "$file" ] || return

   if [ "$( grep "$varname" "${file}" )" ]; then
      local var="$(awk "\$1 ~ /^$2$/ { print \$2 }" $file)"
      if [ "${var}" = "ON" ]; then
         echo "Enabled"
      elif [ "${var}" = "OFF" -o "${var}" = "0" -o -z "${var}" ]; then
         echo "Disabled"
      elif [ "${3:-""}" = "ne" ]; then
         if [ "${var}" != "$4" ]; then
            echo "Enabled"
         else
            echo "Disabled"
         fi
      elif [ "${3:-""}" = "gt" ]; then
         if [ "${var}" -gt "$4" ]; then
            echo "Enabled"
         else
            echo "Disabled"
         fi
      elif [ "${var}" ]; then
         echo "Enabled"
      else
         echo "Disabled"
      fi
   else
      echo "Not Supported"
   fi
}

feat_on_renamed () {
   local file="$1"
   shift;

   for varname in "$@"; do
      local feat_on="$( feat_on "$file" $varname )"
      if [ "${feat_on:-"Not Supported"}" != "Not Supported" ]; then
         echo $feat_on
         return
      fi
   done

   echo "Not Supported"
}

get_mysql_timezone () {
   local file="$1"

   [ -e "$file" ] || return

   local tz="$(get_var time_zone "${file}")"
   if [ "${tz}" = "SYSTEM" ]; then
      tz="$(get_var system_time_zone "${file}")"
   fi
   echo "${tz}"
}

get_cloud_platform () {
   local file="$1"

   local datadir="$(get_var datadir "${file}")"
   local version="$(get_var version "${file}")"

   if [[ $datadir == *"rdsdbdata"* ]]; then
      name_val "Cloud Platform" "Amazon RDS"
   elif [[ $version == *"google"* ]]; then
      name_val "Cloud Platform" "Google CloudSQL"
   elif [[ $datadir == *"vtdataroot"* ]]; then
      name_val "Cloud Platform" "PlanetScale"
   else
      name_val "Cloud Platform" "On-prem / Could not detect"
   fi
}

get_mysql_version () {
   local file="$1"

   name_val Version "$(get_var version "${file}") $(get_var version_comment "${file}")"
   name_val "Built On" "$(get_var version_compile_os "${file}") $(get_var version_compile_machine "${file}")"
}

get_mysql_uptime () {
   local uptime="$1"
   local restart="$2"
   uptime="$(secs_to_time ${uptime})"
   echo "${restart} (up ${uptime})"
}

summarize_binlogs () {
   local file="$1"

   [ -e "$file" ] || return

   local size="$(awk '{t += $2} END{printf "%0.f\n", t}' "$file")"
   name_val "Binlogs" $(wc -l "$file")
   name_val "Zero-Sized" $(grep -c '\<0$' "$file")
   name_val "Total Size" $(shorten ${size} 1)
}

format_table_sizes () {
   local file="$1"
   [ -e "$file" ] || return
   local counter=0
   while read var && [ $counter -lt 21 ]; do
      read -ra arr -d '' <<<"$var"
      name_val "${arr[0]}" "$(shorten ${arr[1]} 0) ${arr[*]:2}"
      let counter=counter+1
   done < "$file"
   
}

format_status_variables () {
   local file="$1"
   [ -e "$file" ] || return

   utime1="$(awk '/Uptime /{print $2}' "$file")";
   utime2="$(awk '/Uptime /{print $3}' "$file")";
   awk "
   BEGIN {
      utime1 = ${utime1};
      utime2 = ${utime2};
      udays  = utime1 / 86400;
      udiff  = utime2 - utime1;
      printf(\"    %-35s %11s %11s %11s\\n\", \"Counter\", \"Per day\", \"Per second\", udiff \" secs\");
   }
   \$2 ~ /^[0-9]{4}-[0-9]{2}-[0-9]{2}.*\$/ {
      printf(\"    %-35s %11s %11s \\n\", \$1, \$2, \$3)
   }
   \$2 ~ /^[0-9]*\$/ {
      if ( \$2 > 0 && \$2 < 18446744073709551615 ) {
         if ( udays > 0 ) {
            fuzzy_var=\$2 / udays;
            ${fuzzy_formula};
            perday=fuzzy_var;
         }
         if ( utime1 > 0 ) {
            fuzzy_var=\$2 / utime1;
            ${fuzzy_formula};
            persec=fuzzy_var;
         }
         if ( udiff > 0 ) {
            fuzzy_var=(\$3 - \$2) / udiff;
            ${fuzzy_formula};
            nowsec=fuzzy_var;
         }
         perday = int(perday);
         persec = int(persec);
         nowsec = int(nowsec);
         if ( perday + persec + nowsec > 0 ) {
            perday_format=\"%11.f\";
            persec_format=\"%11.f\";
            nowsec_format=\"%11.f\";
            if ( perday == 0 ) { perday = \"\"; perday_format=\"%11s\"; }
            if ( persec == 0 ) { persec = \"\"; persec_format=\"%11s\"; }
            if ( nowsec == 0 ) { nowsec = \"\"; nowsec_format=\"%11s\"; }
            format=\"    %-35s \" perday_format \" \" persec_format \" \" nowsec_format \"\\n\";
            printf(format, \$1, perday, persec, nowsec);
         }
      }
   }
   " "$file"
}

summarize_processlist () {
   local file="$1"

   [ -e "$file" ] || return

   for param in Command User Host db State; do
      echo
      printf '    %-30s %8s %7s %9s %9s\n' \
         "${param}" "COUNT(*)" Working "SUM(Time)" "MAX(Time)"
      echo "    ------------------------------" \
         "-------- ------- --------- ---------"
      cut -c1-80 "$file" \
         | awk "
         \$1 == \"${param}:\" {
            p = substr(\$0, index(\$0, \":\") + 2);
            if ( index(p, \":\") > 0 ) {
               p = substr(p, 1, index(p, \":\") - 1);
            }
            if ( length(p) > 30 ) {
               p = substr(p, 1, 30);
            }
         }
         \$1 == \"Time:\" {
            t = \$2;
            if ( t == \"NULL\" ) { 
                t = 0;
            }
         }
         \$1 == \"Command:\" {
            c = \$2;
         }
         \$1 == \"Info:\" {
            count[p]++;
            if ( c == \"Sleep\" ) {
               sleep[p]++;
            }
            if ( \"${param}\" == \"Command\" || c != \"Sleep\" ) {
               time[p] += t;
               if ( t > mtime[p] ) { mtime[p] = t; }
            }
         }
         END {
            for ( p in count ) {
               fuzzy_var=count[p]-sleep[p]; ${fuzzy_formula} fuzzy_work=fuzzy_var;
               fuzzy_var=count[p];          ${fuzzy_formula} fuzzy_count=fuzzy_var;
               fuzzy_var=time[p];           ${fuzzy_formula} fuzzy_time=fuzzy_var;
               fuzzy_var=mtime[p];          ${fuzzy_formula} fuzzy_mtime=fuzzy_var;
               printf \"    %-30s %8d %7d %9d %9d\n\", p, fuzzy_count, fuzzy_work, fuzzy_time, fuzzy_mtime;
            }
         }
      " | sort
   done
   echo
}

pretty_print_cnf_file () {
   local file="$1"

   [ -e "$file" ] || return

   perl -n -l -e '
      my $line = $_;
      if ( $line =~ /^\s*[a-zA-Z[]/ ) { 
         if ( $line=~/\s*(.*?)\s*=\s*(.*)\s*$/ ) { 
            printf("    %-35s = %s\n", $1, $2)  
         } 
         elsif ( $line =~ /\s*\[/ ) { 
            print "\n    $line" 
         } else {
            print "    $line"
         } 
      }' "$file"

}

format_overall_db_stats () {
   local file="$1"
   local tmpfile="$PS_TMPDIR/format_overall_db_stats.tmp"

   [ -e "$file" ] || return

   echo
   awk '
      BEGIN {
         db      = "{chosen}";
         num_dbs = 0;
      }
      /^USE `.*`;$/ {
         db = substr($2, 2, length($2) - 3);
         if ( db_seen[db]++ == 0 ) {
            dbs[num_dbs] = db;
            num_dbs++;
         }
      }
      /^CREATE TABLE/ {
         if (num_dbs == 0) {
            num_dbs     = 1;
            db_seen[db] = 1;
            dbs[0]      = db;
         }
         counts[db ",tables"]++;
      }
      /CREATE ALGORITHM=/ {
         counts[db ",views"]++;
      }
      /03 CREATE.*03 PROCEDURE/ {
         counts[db ",sps"]++;
      }
      /03 CREATE.*03 FUNCTION/ {
         counts[db ",func"]++;
      }
      /03 CREATE.*03 TRIGGER/ {
         counts[db ",trg"]++;
      }
      /FOREIGN KEY/ {
         counts[db ",fk"]++;
      }
      /CASCADE/ {
         counts[db ",casc"]++;
      }
      /PARTITION BY/ {
         counts[db ",partn"]++;
      }
      END {
         mdb = length("Database");
         for ( i = 0; i < num_dbs; i++ ) {
            if ( length(dbs[i]) > mdb ) {
               mdb = length(dbs[i]);
            }
         }
         fmt = "    %-" mdb "s   %6s   %5s   %3s   %5s   %5s   %5s   %4s   %5s\n";
         printf fmt, "Database", "Tables", "Views", "SPs", "Trigs", "Funcs", "FKs", "Casc", "Partn";
         for ( i=0;i<num_dbs;i++ ) {
            db = dbs[i];
            printf fmt, db, counts[db ",tables"], counts[db ",views"], counts[db ",sps"], counts[db ",trg"], counts[db ",func"], counts[db ",fk"], counts[db ",casc"], counts[db ",partn"];
         }
      }
   ' "$file" > "$tmpfile"
   head -n2 "$tmpfile"
   tail -n +3 "$tmpfile" | sort

   echo
   awk '
      BEGIN {
         db          = "{chosen}";
         num_dbs     = 0;
         num_engines = 0;
      }
      /^USE `.*`;$/ {
         db = substr($2, 2, length($2) - 3);
         if ( db_seen[db]++ == 0 ) {
            dbs[num_dbs] = db;
            num_dbs++;
         }
      }
      /^\) ENGINE=/ {
         if (num_dbs == 0) {
            num_dbs     = 1;
            db_seen[db] = 1;
            dbs[0]      = db;
         }
         engine=substr($2, index($2, "=") + 1);
         if ( engine_seen[tolower(engine)]++ == 0 ) {
            engines[num_engines] = engine;
            num_engines++;
         }
         counts[db "," engine]++;
      }
      END {
         mdb = length("Database");
         for ( i=0;i<num_dbs;i++ ) {
            db = dbs[i];
            if ( length(db) > mdb ) {
               mdb = length(db);
            }
         }
         fmt = "    %-" mdb "s"
         printf fmt, "Database";
         for ( i=0;i<num_engines;i++ ) {
            engine = engines[i];
            fmts[engine] = "    %" length(engine) "s";
            printf fmts[engine], engine;
         }
         print "";
         for ( i=0;i<num_dbs;i++ ) {
            db = dbs[i];
            printf fmt, db;
            for ( j=0;j<num_engines;j++ ) {
               engine = engines[j];
               printf fmts[engine], counts[db "," engine];
            }
            print "";
         }
      }
   ' "$file" > "$tmpfile"
   head -n1 "$tmpfile"
   tail -n +2 "$tmpfile" | sort

   echo
   awk '
      BEGIN {
         db        = "{chosen}";
         num_dbs   = 0;
         num_idxes = 0;
      }
      /^USE `.*`;$/ {
         db = substr($2, 2, length($2) - 3);
         if ( db_seen[db]++ == 0 ) {
            dbs[num_dbs] = db;
            num_dbs++;
         }
      }
      /KEY/ {
         if (num_dbs == 0) {
            num_dbs     = 1;
            db_seen[db] = 1;
            dbs[0]      = db;
         }
         idx="BTREE";
         if ( $0 ~ /SPATIAL/ ) {
            idx="SPATIAL";
         }
         if ( $0 ~ /FULLTEXT/ ) {
            idx="FULLTEXT";
         }
         if ( $0 ~ /USING RTREE/ ) {
            idx="RTREE";
         }
         if ( $0 ~ /USING HASH/ ) {
            idx="HASH";
         }
         if ( idx_seen[idx]++ == 0 ) {
            idxes[num_idxes] = idx;
            num_idxes++;
         }
         counts[db "," idx]++;
      }
      END {
         mdb = length("Database");
         for ( i=0;i<num_dbs;i++ ) {
            db = dbs[i];
            if ( length(db) > mdb ) {
               mdb = length(db);
            }
         }
         fmt = "    %-" mdb "s"
         printf fmt, "Database";
         for ( i=0;i<num_idxes;i++ ) {
            idx = idxes[i];
            fmts[idx] = "    %" length(idx) "s";
            printf fmts[idx], idx;
         }
         print "";
         for ( i=0;i<num_dbs;i++ ) {
            db = dbs[i];
            printf fmt, db;
            for ( j=0;j<num_idxes;j++ ) {
               idx = idxes[j];
               printf fmts[idx], counts[db "," idx];
            }
            print "";
         }
      }
   ' "$file" > "$tmpfile"
   head -n1 "$tmpfile"
   tail -n +2 "$tmpfile" | sort

   echo
   awk '
      BEGIN {
         db          = "{chosen}";
         num_dbs     = 0;
         num_types = 0;
      }
      /^USE `.*`;$/ {
         db = substr($2, 2, length($2) - 3);
         if ( db_seen[db]++ == 0 ) {
            dbs[num_dbs] = db;
            num_dbs++;
         }
      }
      /^  `/ {
         if (num_dbs == 0) {
            num_dbs     = 1;
            db_seen[db] = 1;
            dbs[0]      = db;
         }
         str = $0;
         str = substr(str, index(str, "`") + 1);
         str = substr(str, index(str, "`") + 2);
         if ( index(str, " ") > 0 ) {
            str = substr(str, 1, index(str, " ") - 1);
         }
         if ( index(str, ",") > 0 ) {
            str = substr(str, 1, index(str, ",") - 1);
         }
         if ( index(str, "(") > 0 ) {
            str = substr(str, 1, index(str, "(") - 1);
         }
         type = str;
         if ( type_seen[type]++ == 0 ) {
            types[num_types] = type;
            num_types++;
         }
         counts[db "," type]++;
      }
      END {
         mdb = length("Database");
         for ( i=0;i<num_dbs;i++ ) {
            db = dbs[i];
            if ( length(db) > mdb ) {
               mdb = length(db);
            }
         }
         fmt = "    %-" mdb "s"
         mtlen = 0; # max type length
         for ( i=0;i<num_types;i++ ) {
            type = types[i];
            if ( length(type) > mtlen ) {
               mtlen = length(type);
            }
         }
         for ( i=1;i<=mtlen;i++ ) {
            printf "   %-" mdb "s", "";
            for ( j=0;j<num_types;j++ ) {
               type = types[j];
               if ( i > length(type) ) {
                  ch = " ";
               }
               else {
                  ch = substr(type, i, 1);
               }
               printf("  %4s", ch);
            }
            print "";
         }
         printf "    %-" mdb "s", "Database";
         for ( i=0;i<num_types;i++ ) {
            printf "  %4s", "====";
         }
         print "";
         for ( i=0;i<num_dbs;i++ ) {
            db = dbs[i];
            printf fmt, db;
            for ( j=0;j<num_types;j++ ) {
               type = types[j];
               printf "  %4s", counts[db "," type];
            }
            print "";
         }
      }
   ' "$file" > "$tmpfile"
   local hdr=$(grep -n Database "$tmpfile" | cut -d: -f1);
   head -n${hdr} "$tmpfile"
   tail -n +$((${hdr} + 1)) "$tmpfile" | sort
   echo
}

section_noteworthy_variables () {
   local file="$1"

   [ -e "$file" ] || return

   for v in \
      auto_increment_increment auto_increment_offset character_set_server \
      collation_server default_storage_engine \
      innodb_adaptive_checkpoint innodb_adaptive_flushing \
      innodb_buffer_pool_instances innodb_flush_log_at_trx_commit \
      innodb_flush_method innodb_io_capacity innodb_io_capacity_max innodb_log_files_in_group \
      innodb_read_io_threads innodb_thread_concurrency innodb_write_io_threads \
      log_queries_not_using_indexes log_slow_queries long_query_time \
      max_connections optimizer_switch performance_schema sql_mode tx_isolation \
      ;
   do
      name_val "${v}" "$(get_var ${v} "$file")"
   done

   for v in \
      bulk_insert_buffer innodb_buffer_pool_size innodb_log_file_size innodb_log_buffer_size \
      join_buffer_size max_allowed_packet max_heap_table_size read_buffer_size \
      read_rnd_buffer_size sort_buffer_size thread_stack tmp_table_size;
   do
      name_val "${v}" "$(shorten $(get_var ${v} "$file") 0)"
   done
}

counters_pattern () {
   local counters_pattern=""
   for var in Aborted_connects Bytes_received Bytes_sent Com_begin Com_commit Com_delete \
   Com_insert Com_insert_select Com_kill Com_rollback Com_select Com_set_option Com_stmt_execute \
   Com_stmt_close Com_lock_tables Com_stmt_prepare Com_unlock_tables Com_truncate Com_update \
   Connections Innodb_rows_deleted Innodb_rows_inserted Innodb_rows_read Innodb_rows_updated \
   Max_used_connections Max_used_connections_time Queries Questions Select_full_join Select_full_range_join Select_scan \
   Select_range Select_range_check Sort_range Sort_rows Sort_scan Slow_queries Ssl_accepts Threads_cached \
   Threads_connected Threads_created Threads_running;
   do
      if [ -z "${counters_pattern}" ]; then
         counters_pattern="${var}"
      else
         counters_pattern="${counters_pattern}\|${var}"
      fi
   done
   echo $counters_pattern
}

section_mysqld () {
   local executables_file="$1"
   local variables_file="$2"

   [ -e "$executables_file" -a -e "$variables_file" ] || return

   section "MySQL Executable"
   local i=1;
   while read executable; do
      name_val "Path to executable" "$executable"
      name_val "Has symbols" "$( get_var "pt-summary-internal-mysqld_executable_${i}" "$variables_file" )"
      i=$(($i + 1))
   done < "$executables_file"
}

section_percona_xtradb_cluster () {
   local mysql_var="$1"
   local mysql_status="$2"

   name_val "Cluster Name"    "$(get_var "wsrep_cluster_name" "$mysql_var")"
   name_val "Cluster Address" "$(get_var "wsrep_cluster_address" "$mysql_var")"
   name_val "Cluster Size"    "$(get_var "wsrep_cluster_size" "$mysql_status")"
   name_val "Cluster Nodes"   "$(get_var "wsrep_incoming_addresses" "$mysql_status")"

   name_val "Node Name"       "$(get_var "wsrep_node_name" "$mysql_var")"
   name_val "Node Status"     "$(get_var "wsrep_cluster_status" "$mysql_status")"

   name_val "SST Method"      "$(get_var "wsrep_sst_method" "$mysql_var")"
   name_val "Replica Threads"   "$(get_var "wsrep_slave_threads" "$mysql_var")"
   
   name_val "Ignore Split Brain" "$( parse_wsrep_provider_options "pc.ignore_sb" "$mysql_var" )"
   name_val "Ignore Quorum" "$( parse_wsrep_provider_options "pc.ignore_quorum" "$mysql_var" )"
   
   name_val "gcache Size"      "$( parse_wsrep_provider_options "gcache.size" "$mysql_var" )"
   name_val "gcache Directory" "$( parse_wsrep_provider_options "gcache.dir" "$mysql_var" )"
   name_val "gcache Name"      "$( parse_wsrep_provider_options "gcache.name" "$mysql_var" )"
}

parse_wsrep_provider_options () {
   local looking_for="$1"
   local mysql_var_file="$2"

   grep wsrep_provider_options "$mysql_var_file" \
   | perl -Mstrict -le '
      my $provider_opts = scalar(<STDIN>);
      my $looking_for   = $ARGV[0];
      my %opts          = $provider_opts =~ /(\S+)\s*=\s*(\S*)(?:;|$)/g;
      print $opts{$looking_for};
   ' "$looking_for"
}

report_mysql_summary () {
   local dir="$1"

   local NAME_VAL_LEN=35

   local OUTFILE="ps_report_$TIMESTAMP.md"

   section "PlanetScale Migration Pre-Check Report" | tee -a $OUTFILE
   name_val "System time" "`date -u +'%F %T UTC'` (local TZ: `date +'%Z %z'`)" | tee -a $OUTFILE
   echo "" | tee -a $OUTFILE
   
   section "Summary" | tee -a $OUTFILE
   local uptime="$(get_var Uptime "$dir/mysql-status")"
   local uptime_interval=$(echo "$uptime" | cut -f2)
   local rows_read_start="$(get_var "Innodb_rows_read" "$dir/mysql-status")"
   local innodb_rows_deleted="$(get_var "Innodb_rows_deleted" "$dir/mysql-status")"
   local innodb_rows_updated="$(get_var "Innodb_rows_updated" "$dir/mysql-status")"
   local innodb_rows_inserted="$(get_var "Innodb_rows_inserted" "$dir/mysql-status")"
   local rows_written_start=$((innodb_rows_deleted + innodb_rows_updated + innodb_rows_inserted))
   name_val "Rows written since startup" "$rows_written_start" | tee -a $OUTFILE
   name_val "Rows read since startup" "$rows_read_start" | tee -a $OUTFILE
   name_val "Daily average rows written" $((rows_written_start/uptime_interval*60*60*24)) | tee -a $OUTFILE
   name_val "Daily average rows read" $((rows_read_start/uptime_interval*60*60*24)) | tee -a $OUTFILE
   echo "" | tee -a $OUTFILE

   section "Table Information (top 20, approx. row counts)" | tee -a $OUTFILE
   format_table_sizes "$dir/table-sizes" | tee -a $OUTFILE
   echo "" | tee -a $OUTFILE

   local user="$(get_var "pt-summary-internal-user" "$dir/mysql-variables")"
   local port="$(get_var port "$dir/mysql-variables")"
   local now="$(get_var "pt-summary-internal-now" "$dir/mysql-variables")"
   section "Report On Port ${port}" | tee -a $OUTFILE
   name_val User "${user}" | tee -a $OUTFILE
   name_val Time "${now} ($(get_mysql_timezone "$dir/mysql-variables"))" | tee -a $OUTFILE
   name_val Hostname "$(get_var hostname "$dir/mysql-variables")" | tee -a $OUTFILE
   get_mysql_version "$dir/mysql-variables" | tee -a $OUTFILE
   get_cloud_platform "$dir/mysql-variables" | tee -a $OUTFILE


   local uptime="$(get_var Uptime "$dir/mysql-status")"
   local current_time="$(get_var "pt-summary-internal-current_time" "$dir/mysql-variables")"
   name_val Started "$(get_mysql_uptime "${uptime}" "${current_time}")" | tee -a $OUTFILE

   local num_dbs="$(grep -c . "$dir/mysql-databases")"
   name_val Databases "${num_dbs}" | tee -a $OUTFILE
   local datadir=$(get_var datadir "$dir/mysql-variables")
   name_val Datadir "${datadir}" | tee -a $OUTFILE

   local fuzz_procs=$(fuzz $(get_var Threads_connected "$dir/mysql-status"))
   local fuzz_procr=$(fuzz $(get_var Threads_running "$dir/mysql-status"))
   name_val Processes "${fuzz_procs} connected, ${fuzz_procr} running" | tee -a $OUTFILE

   local replica=""
   if [ -s "$dir/mysql-replica" ]; then replica=""; else replica="not "; fi
   local replicacount=$(grep -c 'Binlog Dump' "$dir/mysql-processlist")
   name_val Replication "Is ${replica}a replica, has ${replicacount} replicas connected" | tee -a $OUTFILE

   echo "" | tee -a $OUTFILE
   section "Noteworthy Variables" | tee -a $OUTFILE
   section_noteworthy_variables "$dir/mysql-variables" | tee -a $OUTFILE
   echo "" | tee -a $OUTFILE
   section "Noteworthy Technologies" | tee -a $OUTFILE
   if [ -s "$dir/mysqldump" ]; then
      if grep -i FULLTEXT "$dir/mysqldump" > /dev/null; then
         name_val "Full Text Indexing" "Yes" | tee -a $OUTFILE
      else
         name_val "Full Text Indexing" "No" | tee -a $OUTFILE
      fi
      if grep -i 'GEOMETRY\|POINT\|LINESTRING\|POLYGON' "$dir/mysqldump" > /dev/null; then
         name_val "Geospatial Types" "Yes" | tee -a $OUTFILE
      else
         name_val "Geospatial Types" "No" | tee -a $OUTFILE
      fi
      if grep -i 'FOREIGN KEY' "$dir/mysqldump" > /dev/null; then
         name_val "Foreign Keys" "Yes" | tee -a $OUTFILE
      else
         name_val "Foreign Keys" "No" | tee -a $OUTFILE
      fi
      if grep -i 'PARTITION BY' "$dir/mysqldump" > /dev/null; then
         name_val "Partitioning" "Yes" | tee -a $OUTFILE
      else
         name_val "Partitioning" "No" | tee -a $OUTFILE
      fi
      if grep -e 'ENGINE=InnoDB.*ROW_FORMAT' \
         -e 'ENGINE=InnoDB.*KEY_BLOCK_SIZE' "$dir/mysqldump" > /dev/null; then
         name_val "InnoDB Compression" "Yes" | tee -a $OUTFILE
      else
         name_val "InnoDB Compression" "No" | tee -a $OUTFILE
      fi
   fi
   local ssl="$(get_var Ssl_accepts "$dir/mysql-status")"
   if [ -n "$ssl" -a "${ssl:-0}" -gt 0 ]; then
      name_val "SSL" "Yes" | tee -a $OUTFILE
   else
      name_val "SSL" "No" | tee -a $OUTFILE
   fi
   local lock_tables="$(get_var Com_lock_tables "$dir/mysql-status")"
   if [ -n "$lock_tables" -a "${lock_tables:-0}" -gt 0 ]; then
      name_val "Explicit LOCK TABLES" "Yes" | tee -a $OUTFILE
   else
      name_val "Explicit LOCK TABLES" "No" | tee -a $OUTFILE
   fi
   local xat="$(get_var Com_xa_start "$dir/mysql-status")"
   if [ -n "$xat" -a "${xat:-0}" -gt 0 ]; then
      name_val "XA Transactions" "Yes" | tee -a $OUTFILE
   else
      name_val "XA Transactions" "No" | tee -a $OUTFILE
   fi
   local prep=$(( $(get_var "Com_stmt_prepare" "$dir/mysql-status") + $(get_var "Com_prepare_sql" "$dir/mysql-status") ))
   if [ "${prep}" -gt 0 ]; then
      name_val "Prepared Statements" "Yes" | tee -a $OUTFILE
   else
      name_val "Prepared Statements" "No" | tee -a $OUTFILE
   fi
   echo "" | tee -a $OUTFILE
   section "Processlist" | tee -a $OUTFILE
   summarize_processlist "$dir/mysql-processlist" | tee -a $OUTFILE
   echo "" | tee -a $OUTFILE
   section "Status Counters (Wait ${OPT_SLEEP} Seconds)" | tee -a $OUTFILE
   wait
   local counters_pattern="$(counters_pattern)"
   format_status_variables "$dir/mysql-status-defer" | grep "${counters_pattern}" | tee -a $OUTFILE
   echo "" | tee -a $OUTFILE
   local has_wsrep="$(get_var "wsrep_on" "$dir/mysql-variables")"
   if [ -n "${has_wsrep:-""}" ]; then
      local wsrep_on="$(feat_on "$dir/mysql-variables" "wsrep_on")"
      section "Galera / Percona XtraDB Cluster" | tee -a $OUTFILE
      if [ "${wsrep_on:-""}" = "Enabled" ]; then
         section_percona_xtradb_cluster "$dir/mysql-variables" "$dir/mysql-status" | tee -a $OUTFILE
      else
         name_val "wsrep_on" "OFF" | tee -a $OUTFILE
      fi
      echo "" | tee -a $OUTFILE
   fi

   local has_query_cache=$(get_var have_query_cache "$dir/mysql-variables")
   if [ "$has_query_cache" = 'YES' ]; then
      section "Query cache" | tee -a $OUTFILE
      local query_cache_size=$(get_var query_cache_size "$dir/mysql-variables")
      local used=$(( ${query_cache_size} - $(get_var Qcache_free_memory "$dir/mysql-status") ))
      local hrat=$(fuzzy_pct $(get_var Qcache_hits "$dir/mysql-status") $(get_var Qcache_inserts "$dir/mysql-status"))
      name_val query_cache_type $(get_var query_cache_type "$dir/mysql-variables") | tee -a $OUTFILE
      name_val Size "$(shorten ${query_cache_size} 1)" | tee -a $OUTFILE
      name_val Usage "$(fuzzy_pct ${used} ${query_cache_size})" | tee -a $OUTFILE
      name_val HitToInsertRatio "${hrat}" | tee -a $OUTFILE
      echo "" | tee -a $OUTFILE
   fi

   section "Configuration File" | tee -a $OUTFILE
   local cnf_file="$(get_var "pt-summary-internal-Config_File_path" "$dir/mysql-variables")"

   if [ -n "${cnf_file}" ]; then
      name_val "Config File" "${cnf_file}" | tee -a $OUTFILE
      pretty_print_cnf_file "$dir/mysql-config-file" | tee -a $OUTFILE
   else
      name_val "Config File" "Cannot autodetect or find, giving up" | tee -a $OUTFILE
   fi

   echo "" | tee -a $OUTFILE
   section "Schema" | tee -a $OUTFILE
   if [ -s "$dir/mysqldump" ] \
      && grep 'CREATE TABLE' "$dir/mysqldump" >/dev/null 2>&1; then
         format_overall_db_stats "$dir/mysqldump" | tee -a $OUTFILE
   elif [ ! -e "$dir/mysqldump" -a "$OPT_READ_SAMPLES" ]; then
      echo "Skipping schema analysis because --read-samples $dir/mysqldump " \
         "does not exist" | tee -a $OUTFILE
   elif [ -z "$OPT_DATABASES" -a -z "$OPT_ALL_DATABASES" ]; then
      echo "Specify --databases or --all-databases to dump and summarize schemas" | tee -a $OUTFILE
   else
      echo "Skipping schema analysis due to apparent error in dump file" | tee -a $OUTFILE
   fi

   echo "" | tee -a $OUTFILE
   section "Binary Logging" | tee -a $OUTFILE

   if    [ -s "$dir/mysql-master-logs" ] \
      || [ -s "$dir/mysql-master-status" ]; then
      summarize_binlogs "$dir/mysql-master-logs" | tee -a $OUTFILE
      local format="$(get_var binlog_format "$dir/mysql-variables")"
      name_val binlog_format "${format:-STATEMENT}" | tee -a $OUTFILE
      name_val gtid_mode "$(get_var gtid_mode "$dir/mysql-variables")" | tee -a $OUTFILE
      name_val expire_logs_days "$(get_var expire_logs_days "$dir/mysql-variables")" | tee -a $OUTFILE
      name_val binlog_expire_logs_seconds "$(get_var binlog_expire_logs_seconds "$dir/mysql-variables")" | tee -a $OUTFILE
      name_val sync_binlog "$(get_var sync_binlog "$dir/mysql-variables")" | tee -a $OUTFILE
   fi
   echo "" | tee -a $OUTFILE
   section "The End" | tee -a $OUTFILE
   echo "" | tee -a $OUTFILE

   tar -czf ps_archive_$TIMESTAMP.tgz $OUTFILE $SAMPLES_DIR *questions*.md
}

# ###########################################################################
# End report_mysql_info package
# ###########################################################################

# ########################################################################
# Some global setup is necessary for cross-platform compatibility, even
# when sourcing this script for testing purposes.
# ########################################################################

TOOL="ps-prechecks"

# These vars are declared earlier in the collect_mysql_info package,
# but if they're still undefined here, try to find them in PATH.
[ "$CMD_MYSQL" ]     || CMD_MYSQL="$(_which mysql)"
[ "$CMD_MYSQLDUMP" ] || CMD_MYSQLDUMP="$( _which mysqldump )"

check_mysql () {
   # Check that mysql and mysqldump are in PATH.  If not, we're
   # already dead in the water, so don't bother with cmd line opts,
   # just error and exit.
   [ -n "$(${CMD_MYSQL} --help 2>/dev/null)" ] \
      || die "Cannot execute mysql.  Check that it is in PATH."
   [ -n "$(${CMD_MYSQLDUMP} --help 2>/dev/null)" ] \
      || die "Cannot execute mysqldump.  Check that it is in PATH."

   # Now that we have the cmd line opts, check that we can actually
   # connect to MySQL.
   [ -n "$(${CMD_MYSQL} ${EXT_ARGV} -e 'SHOW STATUS')" ] \
      || die "Cannot connect to MySQL.  Check that MySQL is running and that the options after -- are correct."

}

sigtrap() {
   warn "Caught signal, forcing exit"
   rm_tmpdir
   exit $EXIT_STATUS
}

# ##############################################################################
# The main() function is called at the end of the script.  This makes it
# testable.  Major bits of parsing are separated into functions for testability.
# ##############################################################################
main() {
   # Prepending SIG to these doesn't work with NetBSD's sh
   trap sigtrap HUP INT TERM

   local MYSQL_ARGS="$(mysql_options)"
   EXT_ARGV="$(arrange_mysql_options "$EXT_ARGV $MYSQL_ARGS")"

   # Check if mysql and mysqldump are there, otherwise bail out early.
   # But don't if they passed in --read-samples, since we don't need
   # a connection then.
   [ "$OPT_READ_SAMPLES" ] || check_mysql

   local RAN_WITH="--sleep=$OPT_SLEEP --databases=$OPT_DATABASES --save-samples=$OPT_SAVE_SAMPLES"

   _d "Starting $0 $RAN_WITH"

   # Begin by setting the $PATH to include some common locations that are not
   # always in the $PATH, including the "sbin" locations.  On SunOS systems,
   # prefix the path with the location of more sophisticated utilities.
   export PATH="${PATH}:/usr/local/bin:/usr/bin:/bin:/usr/libexec"
   export PATH="${PATH}:/usr/mysql/bin/:/usr/local/sbin:/usr/sbin:/sbin"
   export PATH="/usr/gnu/bin/:/usr/xpg4/bin/:${PATH}"

   _d "Going to use: mysql=${CMD_MYSQL} mysqldump=${CMD_MYSQLDUMP}"

   # Create the tmpdir for everything to run in
   mk_tmpdir

   # Set DATA_DIR where we'll save collected data files.
   TIMESTAMP=$(date +%Y%m%d%H%M%S)
   local data_dir="$(setup_data_dir "${OPT_SAVE_SAMPLES:-""}")"
   if [ -z "$data_dir" ]; then
      exit $?
   fi

   if [ -n "$OPT_READ_SAMPLES" -a -d "$OPT_READ_SAMPLES" ]; then
      # --read-samples was set and is a directory, so the samples
      # will already be there.
      data_dir="$OPT_READ_SAMPLES"
   else
      # #####################################################################
      # Fetch most info, leave a child in the background gathering the rest
      # #####################################################################
      collect_mysql_info "${data_dir}" 2>"${data_dir}/collect.err"
   fi

   # ########################################################################
   # Format and pretty-print the data
   # ########################################################################
   report_mysql_summary "${data_dir}"

   rm_tmpdir

}

# Execute the program if it was not included from another file.
# This makes it possible to include without executing, and thus test.
if    [ "${0##*/}" = "$TOOL" ] \
   || [ "${0##*/}" = "bash" -a "${_:-""}" = "$0" ]; then

   # Set up temporary dir.
   mk_tmpdir
   # Parse command line options.
   parse_options "$0" "${@:-""}"

   # Verify that --sleep, if present, is positive
   if [ -n "$OPT_SLEEP" ] && [ "$OPT_SLEEP" -lt 0 ]; then
      option_error "Invalid --sleep value: $sleep"
   fi

   usage_or_errors "$0"
   po_status=$?
   rm_tmpdir

   if [ $po_status -ne 0 ]; then
      [ $OPT_ERRS -gt 0 ] && exit 1
      exit 0
   fi

   main "${@:-""}"
fi

# ############################################################################
# Documentation
# ############################################################################
:<<'DOCUMENTATION'
=pod

=head1 NAME

ps-prechecks - Summarizes information about your MySQL instance to help prepare migration into PlanetScale

=head1 SYNOPSIS

Usage: ps-prechecks [OPTIONS]

ps-prechecks summarizes the status and configuration of a MySQL database server 
so that you can learn about it at a glance, as well as allowing you to share the 
relevant information with PlanetScale.  It is not a tuning tool or diagnosis tool.  
It produces a report that is easy to diff and can be pasted into emails without 
losing the formatting.  It should work well on any modern UNIX systems.

ps-prechecks is a heavily modified version of pt-mysql-summary, which is part of the
Percona Toolkit.

=head1 DESCRIPTION

ps-prechecks works by connecting to a MySQL database server and querying
it for status and configuration information.  It saves these bits of data
into files in a temporary directory, and then formats them neatly with awk
and other scripting languages. Finally, it creates an archive containing both
the summary and the relevant files, that can be sent to the PlanetScale team 
for analysis.

To use, simply execute it.  Optionally add a double dash and then the same
command-line options you would use to connect to MySQL, such as the following:

  ps-prechecks --host <hostname> --user <user> --port 3306 --ask-pass

The tool interacts minimally with the server upon which it runs.

=head1 OUTPUT

Many of the outputs from this tool are deliberately rounded to show their
magnitude but not the exact detail.  This is called fuzzy-rounding. The idea
is that it does not matter whether a server is running 918 queries per second
or 921 queries per second; such a small variation is insignificant, and only
makes the output hard to compare to other servers.  Fuzzy-rounding rounds in
larger increments as the input grows.  It begins by rounding to the nearest 5,
then the nearest 10, nearest 25, and then repeats by a factor of 10 larger
(50, 100, 250), and so on, as the input grows.

The following is a sample of the report that the tool produces:

  # PlanetScale Migration Pre-Check Report #####################
                   System time | 2023-01-11 12:20:04 UTC (local TZ: WET +0000)

  # Summary ####################################################
    Rows written since startup | 182808
       Rows read since startup | 334077
    Daily average rows written | 172800
       Daily average rows read | 345600

  # Table Information (in GB) ##################################
                         Total | 0.14
                      salaries | 0.09
                      dept_emp | 0.02
                        titles | 0.02
                     employees | 0.01
                    copy_state | 0.00
                   departments | 0.00
                  dept_manager | 0.00
            resharding_journal | 0.00
             schema_migrations | 0.00
                  vreplication | 0.00
              current_dept_emp | NULL
          dept_emp_latest_date | NULL

The first two sections collect the information that is most relevant to understanding 
which PlanetScale deployment option is right for you, and how the data is currently 
distributed. This is detected by reading the values of various status counters and by 
reading from the INFORMATION_SCHEMA tables. If the user connecting to the database doesn't
have the right permissions to read these sources, these sections may appear empty.

  # Report On Port 3306 ########################################
                          User | admin@%
                          Time | 2023-01-11 12:19:39 (UTC)
                      Hostname | localhost
                       Version | 8.0.18-google (Google)
                      Built On | Linux x86_64
                Cloud Platform | Google CloudSQL
                       Started | 2023-01-10 16:17 (up 0+20:02:34)
                     Databases | 6
                       Datadir | /mysql/datadir/
                     Processes | 6 connected, 2 running
                   Replication | Is not a replica, has 0 replicas connected

This section is a quick summary of the MySQL instance: version, uptime, and
other very basic parameters. The Time output is generated from the MySQL server,
unlike the system date and time printed earlier, so you can see whether the
database and operating system times match.

  # Noteworthy Variables #######################################
          Auto-Inc Incr/Offset | 1/1
        default_storage_engine | InnoDB
                    flush_time | 0
                  init_connect |
                     init_file |
                      sql_mode | ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION
               max_connections | 4030
              optimizer_switch | index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on,engine_condition_pushdown=on,index_condition_pushdown=on,mrr=on,mrr_cost_based=on,block_nested_loop=on,batched_key_access=off,materialization=on,semijoin=on,loosescan=on,firstmatch=on,duplicateweedout=on,subquery_materialization_cost_based=on,use_index_extensions=on,condition_fanout_filter=on,derived_merge=on,use_invisible_indexes=off,skip_scan=on,hash_join=on
                  tx_isolation |
              join_buffer_size | 256k
              sort_buffer_size | 256k
              read_buffer_size | 128k
          read_rnd_buffer_size | 256k
            bulk_insert_buffer | 0.00
           max_heap_table_size | 16M
                tmp_table_size | 16M
            max_allowed_packet | 32M
                  thread_stack | 280k
     innodb_log_files_in_group | 2
           innodb_flush_method | O_DIRECT
innodb_flush_log_at_trx_commit | 1
        innodb_read_io_threads | 4
       innodb_write_io_threads | 4
     innodb_thread_concurrency | 0
      innodb_adaptive_flushing | ON
    innodb_adaptive_checkpoint |
       innodb_buffer_pool_size | 19G
          innodb_log_file_size | 512M
        innodb_log_buffer_size | 16M
              log_slow_queries |
 log_queries_not_using_indexes | OFF

This section shows several noteworthy server configuration variables that might
be important to know about when working with this server.

  # Noteworthy Technologies ####################################
            Full Text Indexing | No
              Geospatial Types | No
                  Foreign Keys | Yes
                  Partitioning | No
            InnoDB Compression | No
                           SSL | No
          Explicit LOCK TABLES | No
               XA Transactions | No
           Prepared Statements | Yes

This section shows some specific technologies used on this server. Some of them
are detected from the schema dump performed for the previous sections; others
can be detected by looking at SHOW GLOBAL STATUS.

  # Processlist ################################################

    Command                        COUNT(*) Working SUM(Time) MAX(Time)
    ------------------------------ -------- ------- --------- ---------
    Binlog Dump                           1       1    150000    150000
    Query                                 1       1         0         0

    User                           COUNT(*) Working SUM(Time) MAX(Time)
    ------------------------------ -------- ------- --------- ---------
    msandbox                              2       2    150000    150000

    Host                           COUNT(*) Working SUM(Time) MAX(Time)
    ------------------------------ -------- ------- --------- ---------
    localhost                             2       2    150000    150000

    db                             COUNT(*) Working SUM(Time) MAX(Time)
    ------------------------------ -------- ------- --------- ---------
    NULL                                  2       2    150000    150000

    State                          COUNT(*) Working SUM(Time) MAX(Time)
    ------------------------------ -------- ------- --------- ---------
    Master has sent all binlog to         1       1    150000    150000
    NULL                                  1       1         0         0

This section is a summary of the output from SHOW PROCESSLIST. Each sub-section
is aggregated by a different item, which is shown as the first column heading.
When summarized by Command, every row in SHOW PROCESSLIST is included, but
otherwise, rows whose Command is Sleep are excluded from the SUM and MAX
columns, so they do not skew the numbers too much. In the example shown, the
server is idle except for this tool itself, and one connected replica, which
is executing Binlog Dump.

The columns are the number of rows included, the number that are not in Sleep
status, the sum of the Time column, and the maximum Time column. The numbers are
fuzzy-rounded.

  # Status Counters (Wait 5 Seconds) ###########################
  Bytes_received                         20000000         225         600
  Bytes_sent                            225000000        2500        4500
  Com_insert                                    1
  Com_select                                50000                       3
  Com_set_option                             6000
  Com_update                                 3000
  Connections                               40000
  Max_used_connections                         35
  Queries                                  125000           1           6
  Questions                                125000           1           6
  Select_full_join                           3500
  Select_range                               3000
  Select_scan                               80000                       2
  Sort_rows                                 35000                       6
  Sort_scan                                 20000                       1
  Threads_connected                            30
  Threads_created                              35
  Threads_running                               1

This section shows selected counters from two snapshots of SHOW GLOBAL STATUS,
gathered approximately 10 seconds apart and fuzzy-rounded.

The first column is the variable name, and the second column is the counter from
the first snapshot divided by 86400 (the number of seconds in a day), so you can
see the magnitude of the counter's change per day. 

The third column is the value from the first snapshot, divided by Uptime and
then fuzzy-rounded, so it represents approximately how quickly the counter is
growing per-second over the uptime of the server.

The third column is the incremental difference from the first and second
snapshot, divided by the difference in uptime and then fuzzy-rounded. Therefore,
it shows how quickly the counter is growing per second at the time the report
was generated.

  # Configuration File #########################################
                Config File | /tmp/12345/my.sandbox.cnf
  [client]
  user                                = msandbox
  password                            = msandbox
  port                                = 12345
  socket                              = /tmp/12345/mysql_sandbox12345.sock
  [mysqld]
  port                                = 12345
  socket                              = /tmp/12345/mysql_sandbox12345.sock
  pid-file                            = /tmp/12345/data/mysql_sandbox12345.pid
  basedir                             = /home/baron/5.5.20
  datadir                             = /tmp/12345/data
  key_buffer_size                     = 16M
  innodb_buffer_pool_size             = 16M
  innodb_data_home_dir                = /tmp/12345/data
  innodb_log_group_home_dir           = /tmp/12345/data
  innodb_data_file_path               = ibdata1:10M:autoextend
  innodb_log_file_size                = 5M
  log-bin                             = mysql-bin
  relay_log                           = mysql-relay-bin
  log_slave_updates
  server-id                           = 12345
  report-host                         = 127.0.0.1
  report-port                         = 12345
  log-error                           = mysqld.log
  innodb_lock_wait_timeout            = 3

In case the tool is run locally on the machine your MySQL Server is running on,
this section shows a pretty-printed version of the my.cnf file, with comments
removed and with whitespace added to align things for easy reading. The tool
tries to detect the my.cnf file by looking at the output of ps, and if it does
not find the location of the file there, it tries common locations until it
finds a file. Note that this file might not actually correspond with the server
from which the report was generated. This can happen when the tool is run against
a cloud environment, or is run remotely against the same server it's reporting on, 
or when detecting the location of the configuration file fails.

  # Schema #####################################################

    Database  Tables Views SPs Trigs Funcs   FKs Casc Partn
    employees      6     2                     6    6
  
    Database  InnoDB
    employees      6
  
    Database  BTREE
    employees    15
  
                c   v   i   d   e
                h   a   n   a   n
                a   r   t   t   u
                r   c       e   m
                    h
                    a
                    r
    Database  === === === === ===
    employees   3   4   6  10   1

If you specify L<"--databases"> or L<"--all-databases">, the tool will print
the above section. This summarizes the number and type of objects in the
databases. It is generated by running C<mysqldump --no-data>, not by querying
the INFORMATION_SCHEMA, which can freeze a busy server.

The first sub-report in the section is the count of objects by type in each
database: tables, views, and so on. The second one shows how many tables use
various storage engines in each database. The third sub-report shows the number
of each type of indexes in each database.

The last section shows the number of columns of various data types in each
database. For compact display, the column headers are formatted vertically, so
you need to read downwards from the top. In this example, the first column is
C<char> and the second column is C<timestamp>. This example is truncated so it
does not wrap on a terminal.

All of the numbers in this portion of the output are exact, not fuzzy-rounded.

  # Binary Logging #############################################
                       Binlogs | 2
                    Zero-Sized | 0
                    Total Size | 5.1M
                 binlog_format | ROW
              expire_logs_days | 0
                   sync_binlog | 1

This section shows configuration and status of the binary logs. If there are
zero-sized binary logs, then it is possible that the binlog index is out of sync
with the binary logs that actually exist on disk.

=head1 RISKS

ps-prechecks is designed to connect to your live database environment,
execute queries to collect the relevant information, and process/summarize 
the data without further impacting your database environment. While this
scipt is well tested, any database tool can pose a risk to your database
environment.

Before using this tool, please:

=over

=item * Read the tool's documentation

=item * Test the tool on a non-production server first

=item * Backup your production server and verify the backups

=back

=head1 OPTIONS

All options after -- are passed to C<mysql>.

=over

=item --all-databases

type: bool; default: TRUE

mysqldump and summarize all databases.  See L<"--databases">.

=item --ask-pass

Prompt for a password when connecting to MySQL.

=item --config

type: string

Read this comma-separated list of config files.  If specified, this must be the
first option on the command line.

=item --databases

type: string

mysqldump and summarize this comma-separated list of databases.  Specify
L<"--all-databases"> instead if you want to dump and summary all databases.

=item --defaults-file

short form: -F; type: string

Only read mysql options from the given file.  You must give an absolute
pathname.

=item --help

Print help and exit.

=item --host

short form: -h; type: string

Host to connect to.

=item --txt

Generate output using plain text format instead of MarkDown.

=item --password

short form: -p; type: string

Password to use when connecting.
If password contains commas they must be escaped with a backslash: "exam\,ple"

=item --port

short form: -P; type: int

Port number to use for connection.

=item --read-samples

type: string

Create a report from the files found in this directory.

=item --save-samples

type: string

Save the data files used to generate the summary in this directory.

=item --sleep

type: int; default: 10

Seconds to sleep when gathering status counters.

=item --socket

short form: -S; type: string

Socket file to use for connection.

=item --user

short form: -u; type: string

User for login if not current user.

=item --version

Print tool's version and exit.

=back

=head1 ENVIRONMENT

This tool does not use any environment variables.

=head1 SYSTEM REQUIREMENTS

This tool requires Bash v3 or newer, Perl 5.8 or newer, and binutils.
These are generally already provided by most distributions.
On BSD systems, it may require a mounted procfs.

=head1 BUGS

Please report bugs to liz@planetscale.com, or the PlanetScale representative you're working with.
Include the following information in your bug report:

=over

=item * Complete command-line used to run the tool

=item * Tool L<"--version">

=item * MySQL version of all servers involved

=item * Output from the tool including STDERR

=item * Input files (log/dump/config files, etc.)

=back

If possible, include debugging output by running the tool with C<PSDEBUG>;
see L<"ENVIRONMENT">.

=head1 ATTENTION

Using <PSDEBUG> might expose passwords. When debug is enabled, all command line 
parameters are shown in the output.

=head1 AUTHORS

Baron Schwartz, Brian Fraser, Daniel Nichter and Liz van Dijk

=head1 ABOUT PERCONA TOOLKIT

This tool is a heavily modified version of pt-mysql-summary, which is part 
of Percona Toolkit, a collection of advanced command-line tools for MySQL 
developed by Percona.  Percona Toolkit was forked from two
projects in June, 2011: Maatkit and Aspersa.  Those projects were created by
Baron Schwartz and primarily developed by him and Daniel Nichter.  Visit
L<http://www.percona.com/software/> to learn about other free, open-source
software from Percona.

=head1 COPYRIGHT, LICENSE, AND WARRANTY

This program is copyright 2011-2021 Percona LLC and/or its affiliates,
2010-2011 Baron Schwartz.

THIS PROGRAM IS PROVIDED "AS IS" AND WITHOUT ANY EXPRESS OR IMPLIED
WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation, version 2; OR the Perl Artistic License.  On UNIX and similar
systems, you can issue `man perlgpl' or `man perlartistic' to read these
licenses.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place, Suite 330, Boston, MA  02111-1307  USA.

=head1 VERSION

ps-prechecks 1.1

=cut

DOCUMENTATION
